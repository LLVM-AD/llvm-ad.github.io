---
layout: page
permalink: /challenge/
title: Challenges
description: 
nav: false
nav_order: 3
---

TBD

<!-- ### Two Open-Source Datasets 

Two open-source datasets are provided for this workshop. The first dataset focuses on extracting traffic language from HD maps to aid in traffic scenario comprehension through LLMs. The second dataset aims to categorize textbased driver commands to improve human-vehicle language understanding. While using the datasets is recommended, it is **not mandatory** for participation. Both datasets will be released on **Sep. 15th**. 

#### Dataset 1
TBD

#### Dataset 2
TBD -->

<!-- Two open-source datasets are provided for this workshop. The first dataset focuses on extracting traffic language from
HD maps to aid in traffic scenario comprehension through LLVMs. The second dataset aims to categorize textbased driver
commands to improve human-vehicle language understanding. While using the datasets is recommended, it is
**not mandatory** for participation.  -->

<!-- **❗Important Note: This challenge will use our soon-to-be-released MAPLM-QA v1.5 dataset on August 5th, which includes more and higher quality QA data. Please stay tuned!** -->

<!-- **❗ The MAPLM-QA v2.0 dataset has been released at [this link](https://huggingface.co/datasets/LLVM-AD/maplm_v2)**.


The challenge track is based on the **MAPLM-QA benchmark**, a subset of the MAPLM dataset designed for visual question answering in traffic scene understanding. Participants will develop innovative methods to accurately answer multi-choice questions about complex traffic scenes using high-resolution panoramic images and 2.5D bird's-eye view representations. Top-performing teams will be recognized with certificates and honorariums. Detailed information about the challenge can be found in the [MAPLM-QA v2.0 dataset](https://huggingface.co/datasets/LLVM-AD/maplm_v2).

**Please submit your results by filling out this [form](https://forms.office.com/r/mapGsGWQNf). This will allow us to update your results on the leaderboard. The deadline of the challenge is <span style="color:red">Jan 5th</span>.**


### Citation       
If the code, datasets, and research behind this workshop inspire you, please cite our work:      
```
@inproceedings{cao2024maplm,
  title={MAPLM: A Real-World Large-Scale Vision-Language Benchmark for Map and Traffic Scene Understanding},
  author={Cao, Xu and Zhou, Tong and Ma, Yunsheng and Ye, Wenqian and Cui, Can and Tang, Kun and Cao, Zhipeng and Liang, Kaizhao and Wang, Ziran and Rehg, James M and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={21819--21830},
  year={2024}
}
``` -->
