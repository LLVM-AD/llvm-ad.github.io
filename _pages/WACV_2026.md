---
layout: about
title: LLVM-AD @ WACV 2026
permalink: /WACV_2026/
subtitle:
nav: false

# profile:
#   align: 
#   image: 
#   image_circular: false # crops the image to make it circular
#   address: 

news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---

----------
# LLVM-AD @ WACV 2026

### About the Workshop
The 5th Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD) at [WACV 2026](https://wacv.thecvf.com/) aims to bring together professionals from academia and industry to explore the applications of large language and vision models in autonomous driving. We are particularly interested in bridging the gap between the rich image and language data found within the context of autonomous driving. Our primary areas of interest are: a) Traffic Scene Understanding enhanced by VLMs and 
b) Human-Autonomy Teaming driven by LLMs. The topics include but not limited to

- Large Language Models and Vision Language Models for Autonomous Driving
- Multimodal Motion Planning and Prediction
- New Dataset for Autonomous Driving
- Semantics and Scene Understanding in Autonomous Driving
- Language-Driven Sensor and Traffic Simulation
- Domain Adaptation and Transfer Learning in Autonomous Driving
- Multi-Modal Fusion for Autonomous Driving
- Survey and Prospective Paper for Autonomous Driving
- Other Applications of Language or Vision Models for Driving

The schedule will be available [here](/schedule_wacv_2026).

### Accepted Papers
**ðŸŽ‰ We would like to congrats the following papers for being accepted to 5th LLVM-AD!**
- Lightweight Multi-Scale Fusion for Real-Time Autonomous Driving Segmentation
- FROST-Drive: Scalable and Efficient End-to-End Driving with a Frozen Vision Encoder
- Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression
- Benchmarking Vision-Language Models for Traffic Scene Understanding in Inclement Winter Weather: The AWDB Benchmark
- Role of Language-Guidance in Knowledge Distillation for Semantic Segmentation Under Limited Field-Of-View Autonomous Driving
- Less Is More: Agentic Prompt Design for Safe VLM Action Selection
- Trust-Guided Multimodal LLM Integration with Reinforcement Learning for Autonomous Driving
- VLA4CoDrive: Visionâ€“Languageâ€“Action Dataset for Cooperative Autonomous Driving
- 2COOOL: An Evaluation Benchmark for Generating Incident Reports on Out-of-Distribution Hazards in Autonomous Driving
- GATEPose: A Graph Attention Transformer Enhanced with Pose and Orientation Angles for Pedestrian Crossing Intention Prediction

### Call for Papers

The workshop papers will be published in IEEE Xplore as WACV 2026 Workshop Proceedings and will be indexed separately from the main conference proceedings. The papers submitted to the workshop should follow the same formatting requirements as the main conference.

The manuscripts should be of 6 to 8 pages. Submissions are expected to follow the same guidelines as those for WACV's main conference papers. 
<!-- Best papers elected by the committee will have the opportunity to receive the outstanding paper award and \$300 in recognition of their outstanding contributions. -->

Please refer to [page of call for papers](/call_for_papers/) for more details.

### Sponsors

TBD

----------

### Important Dates

- Paper Submission Deadline: December 16th, 11:59PM PST, 2025
- Author Notification Deadline: January 4nd, 11:59PM PST, 2026
<!-- - Camera-Ready Deadline: January 8, 11:59PM PST, 2026  -->
- Workshop Date: March 7th PM, 2026

----------


### Keynote Speakers
<div class="row projects pt-1 pb-1">
      <div class="col-sm-4">
          {% include people.html name="Litian Liu" affiliation="Qualcomm" url="https://litianliu.github.io/" img="https://litianliu.github.io/assets/img/prof_pic.jpg?0f86e7255c77a6dfd89f051d80803a8d" %}
      </div>
</div>
----------

### Program Committee
- [Umar Farooqi](https://ufarooqi.com)
- [Twinkle Joshi](https://www.linkedin.com/in/twinkle-j-joshi) (Senior QA Test Engineer )
- [Juanwu Lu](https://juanwulu.github.io/) (Purdue University) 
- [Gokul Srinath Seetha Ram](https://www.linkedin.com/in/gokulsrinath/) (Independent Researcher)
- Yunfan Wang (University of Virginia)
- Yuping Wang (Woven by Toyota)
- [Zongpu Zhang](https://sites.google.com/view/zpzhang) (Purdue University)

We would also like to thank the reviewers who wish to remain anonymous.

----------

### Organizers

<div class="row row-cols-2 projects pt-3 pb-3">
  {% include people_horizontal.html name="Jiaru Zhang" affiliation="Purdue University" url="https://jiaruzhang.github.io/" img="assets/img/itsc_headshots/jiaru.jpg" %}
  {% include people_horizontal.html name="Can Cui" affiliation="Purdue University" url="https://cancui19.github.io/" img="assets/img/itsc_headshots/linkedin-company-logo-can_cui.jpg" %}
  {% include people_horizontal.html name="SungYeon Park" affiliation="Purdue University" url="https://sungyeonparkk.github.io/about/" img="assets/img/sung-yeon-new.webp" %}
  {% include people_horizontal.html name="Juntong Peng" affiliation="Purdue University" url="https://juntongpeng.github.io/" img="assets/img/Juntong.png" %}
  {% include people_horizontal.html name="Yifan Shen" affiliation="University of Illinois Urbana-Champaign" url="https://shenyifans.github.io/" img="assets/img/itsc_headshots/yifan.jpg" %}
  {% include people_horizontal.html name="Bohan Liu" affiliation="University of Virginia" url="https://www.linkedin.com/in/bohanliu524/" img="assets/img/bohanliu.jpeg" %}
  {% include people_horizontal.html name="Xiangbo Gao" affiliation="Texas A&M University" url="https://www.xiangbogao.com/" img="assets/img/XiangboGao.webp" %}
  {% include people_horizontal.html name="Zhengzhong Tu" affiliation="Texas A&M University" url="https://vztu.github.io/" img="assets/img/itsc_headshots/linkedin-company-logo-zhengzhong.jpeg" %}
  {% include people_horizontal.html name="Jiachen Li" affiliation="UC Riverside" url="https://jiachenli94.github.io/" img="assets/img/itsc_headshots/jiachen.jpg" %}
  {% include people_horizontal.html name="Ismini Lourentzou" affiliation="University of Illinois Urbana-Champaign" url="https://isminoula.github.io/" img="assets/img/itsc_headshots/ismini.jpg" %}
  {% include people_horizontal.html name="Ruqi Zhang" affiliation="Purdue University" url="https://ruqizhang.github.io/" img="https://ruqizhang.github.io/images/portrait.jpg" %}
  {% include people_horizontal.html name="Ziran Wang" affiliation="Purdue University" url="https://ziranw.github.io/" img="assets/img/itsc_headshots/linkedin-company-logo-ziran.jpg" %}

</div>

------

### Contact Emails

For any questions, please feel free to contact <a href="mailto:jiaru@purdue.edu">jiaru@purdue.edu</a>.


