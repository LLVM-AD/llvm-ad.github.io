---
layout: page
permalink: /schedule/
title: Schedule
description:
nav: true
nav_order: 4
---

**Workshop Date:** March 4, 2025 (MST) \
**Workshop Location:** AZ Ballroom Salon 12 \
**Zoom:** [https://purdue-edu.zoom.us/j/96964702241](https://purdue-edu.zoom.us/j/96964702241)

**Please find the workshop schedule below (MST):**

| Time           | Event                                                     |
|----------------|-----------------------------------------------------------|
| 13:00 -- 13:10 | Opening Remarks                                           |
| 13:10 -- 13:40 | **Keynote: Representation Alignment for Autonomous Driving (Dr. Burhan Yaman)**                                                   |
| 13:40 -- 13:50 | Paper Presentation: Language-Driven Active Learning for Diverse Open-Set 3D Object Detection           |
| 13:50 -- 14:00 | Paper Presentation: Scenario understanding of traffic scenes through Large Visual Language Models           |
| 14:00 -- 14:10 | Paper Presentation: Enhancing Weakly-Supervised Object Detection on Static Images through (Hallucinated) Motion           |
| 14:10 -- 14:20 | Paper Presentation: Query3D: LLM-Powered Open-Vocabulary Scene Segmentation with Language Embedded 3D Gaussians           |
| 14:20 -- 14:50 | **Keynote: Towards Safe Open-World Autonomy (Dr. Manmohan Chandraker)**                                                   |
| 14:50 -- 15:10 | Coffee Break                                              |
| 15:10 -- 15:20 | Paper Presentation: ScVLM: Enhancing Vision-Language Model for Safety-Critical Event Understanding           |
| 15:20 -- 15:30 | Paper Presentation: VLMine: Long-Tail Data Mining with Vision Language Models           |
| 15:30 -- 15:40 | Paper Presentation: SenseRAG: Constructing Environmental Knowledge Bases with Proactive Querying for LLM-Based Autonomous Driving          |
| 15:40 -- 16:10 | **Keynote: Fast-Slow Dual Autonomous Driving Systems (Dr. Hang Zhao)**                                                   |
| 16:10 -- 16:20 | Paper Presentation: Glimpse of MCQ based VQA in Road & Traffic Scenarios          |
| 16:20 -- 16:30 | Paper Presentation: OpenEMMA: Open-Source Multimodal Model for End-to-End Autonomous Driving          |
| 16:30 -- 16:40 | Paper Presentation: Evaluating Multimodal Vision-Language Model Prompting Strategies for Visual Question Answering in Road Scene Understanding          |
| 16:40 -- 17:00 | Summary & Closing Remarks                                 |