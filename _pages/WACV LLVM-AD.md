---
layout: about
title: LLVM-AD
permalink: /
subtitle: 

# profile:
#   align: 
#   image: 
#   image_circular: false # crops the image to make it circular
#   address: 

news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page
---


<!-- 
Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com). You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any of these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/) and [Academicons](https://jpswalsh.github.io/academicons/), like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them. -->

<!-- ### About LLVM-AD -->
The 1st [WACV](https://wacv2023.thecvf.com/) Workshop on **Large Language and Vision Models for Autonomous Driving (LLVM-AD)** seeks to bring together academia and industry professionals in a collaborative exploration of applying large language and vision models to autonomous driving. Through a half-day in-person event, the workshop will showcase regular and demo paper presentations and invited talks from famous researchers in academia and industry. Additionally, LLVM-AD will launch two open-source real-world traffic language understanding datasets, catalyzing practical advancements. The workshop will host two challenges based on this dataset to assess the capabilities of language and computer vision models in addressing autonomous driving challenges.

----------
### Important Dates

- Paper submission deadline: October 11th, 2023
- Author notification: November 9th, 2023
- Camera-ready papers due: November 19th, 2023
  


----------
### Submission Guidelines
We accept submissions through our CMT. Submissions can be from any subfield of machine learning or related fields of interest subject to the workshop theme. The main goal is to exploring the challenges and immense potential to unlock new horizons in the next-generation landscape of autonomous driving using LLVMs.

----------
### Invited Speakers

TBD

----------
### Organizers

<!-- <table style="width:75%">
  <tr>
    <td style="text-align:center"><img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=6A1yEFMAAAAJ&citpid=1" height="170"></td>
    <td style="text-align:center"><img src="https://www.is.mpg.de/uploads/employee/image/145/L1170153.jpg" height="170"></td>
    <td style="text-align:center"><img src="https://images.ctfassets.net/8wprhhvnpfc0/6hLLZq4X1hVzRGwwrIQOvc/9791f266fcb65b02c3aec680de7dd023/Deborah_Raji_headshot.jpg" height="170"></td>
    <td style="text-align:center"><img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=oXWRBrwAAAAJ&citpid=25" height="170"></td>
  </tr>
  <tr>
    <td style="text-align:center"><a href="http://tensorlab.cms.caltech.edu/users/anima/">Chao Zheng</a> <br> Tencent</td>
    <td style="text-align:center"><a href="https://www.is.mpg.de/~bs">Kun Tang</a> <br>Tencent</td>
    <td style="text-align:center"><a href="https://ainowinstitute.org/people/deborah-raji.html">Zhipeng Cao</a> <br> Tencent</td>
    <td style="text-align:center"><a href="https://www.cs.toronto.edu/~cmaddis/">Xu Cao</a> <br> PediaMed AI </td>
  </tr>
  <tr>
    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/yunsheng.jpg" height="170"></td>
    <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/can.jpg" height="170"></td>
    <td style="text-align:center"><img src="https://wenqian-ye.github.io/images/selfie.jpeg" height="170"></td>
    <td style="text-align:center"><img src="https://dyogatama.github.io/index_files/dy_2.jpg" height="170"></td>
  </tr>
  <tr>
  <td style="text-align:center"><a href="https://pascale.home.ece.ust.hk/">Yunsheng Ma</a> <br> Purdue</td>
    <td style="text-align:center"><a href="https://www.peterhenderson.co/">Can Cui</a> <br> Purdue</td>
    <td style="text-align:center"><a href="http://www.m-mitchell.com/">Wenqian Ye</a> <br> UVA</td>
    <td style="text-align:center"><a href="https://dyogatama.github.io/">Shawn Mei</a> <br> Tencent</td>
  </tr>
</table> -->

- Chao Zheng (Tencent)
- Kun Tang (Tencent)
- Zhipeng Cao (Tencent)
- Xu Cao (PediaMed AI)
- Yunsheng Ma (Purdue)
- Can Cui (Purdue)
- Wenqian Ye (UVA)
- Shawn Mei (Tencent)


----------
### Program Committee
- Ziran Wang (Purdue)
- Yang Zhou (NYU)
- Kaizhao Liang (SambaNova Systems)
- Tianren Gao (SambaNova Systems)
- Kuei-Da Liao (SambaNova Systems)
- Shan Bao (University of Michigan, Transportation Research Institute)



