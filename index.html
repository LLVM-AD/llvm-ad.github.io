<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>LLVM-AD Workshop @ WACV 2024</title> <meta name="author" content=" "> <meta name="description" content="The 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD). "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://llvm-ad.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">LLVM-AD<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/call_for_papers/">Call for Papers</a> </li> <li class="nav-item "> <a class="nav-link" href="/challenges/">Challenges</a> </li> <li class="nav-item "> <a class="nav-link" href="/schedule/">Schedule</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <header class="post-header"> <div class="header-background"></div> <h3 class="post-description"></h3> </header> <div class="post"> <header class="post-header"> <h1 class="post-title"> LLVM-AD Workshop @ WACV 2024 </h1> <p class="desc"></p> </header> <article> <div class="clearfix"> <p>The 1st <a href="https://wacv2024.thecvf.com/" rel="external nofollow noopener" target="_blank">WACV</a> Workshop on <strong>Large Language and Vision Models for Autonomous Driving ( LLVM-AD)</strong> seeks to bring together academia and industry professionals in a collaborative exploration of applying large language and vision models to autonomous driving. Through a half-day in-person event, the workshop will showcase regular and demo paper presentations and invited talks from famous researchers in academia and industry. Additionally, LLVM-AD will launch two open-source real-world traffic language understanding datasets, catalyzing practical advancements. The workshop will host two challenges based on this dataset to assess the capabilities of language and computer vision models in addressing autonomous driving challenges.</p> <p><strong>Note for Benchmark:</strong> The workshop challenge will be maintained in the long term, and even after the workshop concludes, we will continue to welcome submissions of new results on the datasets. We will also update the benchmark accordingly.</p> <p><strong>Note for Submission:</strong> In light of the extension of final decision release for the WACV 2024 main conference, we decided to extend our submission deadline to <strong>October 26th, 2023</strong>.</p> <hr> <h2 id="important-dates">Important Dates</h2> <ul> <li>Paper Submission Deadline: <del>October 23rd, 2023</del> <span style="color:red">October 26th, 2023</span> </li> <li>Author Notification: November 13th, 2023</li> <li>Camera-ready Papers Deadline: November 19th, 2023</li> </ul> <hr> <h2 id="invited-speakers">Invited Speakers</h2> <div style="overflow-x: auto;"> <table style="width:75%"> <tr> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/zhen_li.png" height="150"></td> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/oleg.png" height="150"></td> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/yu_huang.jpg" height="150"></td> </tr> <tr> <td style="text-align:center"> <a href="https://mypage.cuhk.edu.cn/academics/lizhen/" rel="external nofollow noopener" target="_blank">Dr. Zhen Li</a> <br>Assistant Professor, CUHK</td> <td style="text-align:center"> <a href="https://www.linkedin.com/in/oleg-sinavski/" rel="external nofollow noopener" target="_blank">Dr. Oleg Sinavski</a> <br> Principal Applied Scientist, Wayve</td> <td style="text-align:center"> <a href="https://www.linkedin.com/in/yuhuang/" rel="external nofollow noopener" target="_blank">Dr. Yu Huang</a> <br> CEO and Chief Scientist, roboraction.ai</td> </tr> </table> </div> <hr> <h2 id="organizers">Organizers</h2> <div style="overflow-x: auto;"> <table style="width:75%"> <tr> <td style="text-align:center"><img src="https://scholar.googleusercontent.com/citations?view_op=medium_photo&amp;user=6A1yEFMAAAAJ&amp;citpid=1" height="100"></td> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/Kun_Tang.jpg" height="100"></td> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/Zhipeng_Cao.jpg" height="100"></td> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/Xu_Cao.jpg" height="100"></td> <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/yunsheng.jpg" height="100"></td> </tr> <tr> <td style="text-align:center"> <a href="">Chao Zheng</a> <br> Tencent</td> <td style="text-align:center"> <a href="">Kun Tang</a> <br>Tencent</td> <td style="text-align:center"> <a href="">Zhipeng Cao</a> <br>Tencent</td> <td style="text-align:center"> <a href="https://www.linkedin.com/in/irohxu/" rel="external nofollow noopener" target="_blank">Xu Cao</a> <br>PediaMed AI &amp; UIUC</td> <td style="text-align:center"> <a href="https://maysonma.github.io/" rel="external nofollow noopener" target="_blank">Yunsheng Ma</a> <br>Purdue University</td> </tr> <tr> <td style="text-align:center"><img src="https://purduedigitaltwin.github.io/assets/images/people/can.jpg" height="100"></td> <td style="text-align:center"><img src="https://wenqian-ye.github.io/images/selfie.jpeg" height="100"></td> <td style="text-align:center"><img src="https://ziranw.github.io/Attachments/Ziran_Headshot.jpg" height="100"></td> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/Shawn_Mei.png" height="100"></td> <td style="text-align:center"><img src="https://raw.githubusercontent.com/LLVM-AD/llvm-ad.github.io/main/assets/img/Tong_Zhou.jpg" height="100"></td> </tr> <tr> <td style="text-align:center"> <a href="https://cancui19.github.io/" rel="external nofollow noopener" target="_blank">Can Cui</a> <br> Purdue University</td> <td style="text-align:center"> <a href="https://wenqian-ye.github.io/" rel="external nofollow noopener" target="_blank">Wenqian Ye</a> <br> PediaMed AI &amp; UVA </td> <td style="text-align:center"> <a href="https://ziranw.github.io" rel="external nofollow noopener" target="_blank">Ziran Wang</a> <br>Purdue University</td> <td style="text-align:center"> <a href="">Shawn Mei</a> <br> Tencent</td> <td style="text-align:center"> <a href="">Tong Zhou</a> <br> Tencent</td> </tr> </table> </div> <hr> <h2 id="summary-and-accepted-papers">Summary and Accepted Papers</h2> <p><strong>Summary of the 1st WACV Workshop on Large Language and Vision Models for Autonomous Driving (LLVM-AD)</strong></p> <table> <tbody> <tr> <td><a href="https://arxiv.org/abs/2311.12320" rel="external nofollow noopener" target="_blank">Arxiv</a></td> <td><a href="https://github.com/IrohXu/Awesome-Multimodal-LLM-Autonomous-Driving" rel="external nofollow noopener" target="_blank">GitHub</a></td> </tr> </tbody> </table> <p><strong>ðŸŽ‰ We would like to congrate the following papers for being accepted to LLVM-AD 2024!</strong></p> <ul> <li> <p><a href="https://arxiv.org/abs/2309.10228" rel="external nofollow noopener" target="_blank">Drive as You Speak: Enabling Human-Like Interaction with Large Language Models in Autonomous Vehicles</a></p> </li> <li> <p><a href="https://arxiv.org/abs/2307.07162" rel="external nofollow noopener" target="_blank">Drive Like a Human: Rethinking Autonomous Driving with Large Language Models</a></p> </li> <li> <p><a href="https://arxiv.org/abs/2308.13270" rel="external nofollow noopener" target="_blank">A Game of Bundle Adjustment - Learning Efficient Convergence</a> Accepted as a tech report for ICCV 2023 Paper</p> </li> <li> <p>VLAAD: Vision and Language Assistant for Autonomous Driving</p> </li> <li> <p>A Safer Vision-based Autonomous Planning System for Quadrotor UAVs with Dynamic Obstacle Trajectory Prediction and Its Application with LLMs</p> </li> <li> <p><a href="https://arxiv.org/abs/2311.08206" rel="external nofollow noopener" target="_blank">Human-Centric Autonomous Systems With LLMs for User Command Reasoning</a></p> </li> <li> <p>NuScenes-MQA: Integrated Evaluation of Captions and QA for Autonomous Driving Datasets using Markup Annotations</p> </li> <li> <p>Latency Driven Spatially Sparse Optimization for Multi-Branch CNNs for Semantic Segmentation</p> </li> <li> <p>LIP-Loc: LiDAR Image Pretraining for Cross-Modal Localization</p> </li> </ul> <hr> <h2 id="challenge-organization-committee">Challenge Organization Committee</h2> <ul> <li>Chao Zheng (Tencent)</li> <li>Kun Tang (Tencent)</li> <li>Zhipeng Cao (Tencent)</li> <li>Tong Zhou (Tencent)</li> <li>Erlong Li (Tencent)</li> <li>Ao Liu (Tencent)</li> <li>Shengtao Zou (Tencent)</li> <li>Xinrui Yan (Tencent)</li> <li>Shawn Mei (Tencent)</li> <li>Yunsheng Ma (Purdue University)</li> <li>Can Cui (Purdue University)</li> <li>Ziran Wang (Purdue University)</li> <li>Yang Zhou (New York University)</li> <li>Kaizhao Liang (SambaNova Systems)</li> <li>Wenqian Ye (PediaMed AI &amp; University of Virginia)</li> <li>Xu Cao (PediaMed AI &amp; University of Illinois Urbana-Champaign)</li> </ul> <hr> <h2 id="program-committee">Program Committee</h2> <ul> <li>Erlong Li (Tencent)</li> <li>Ao Liu (Tencent)</li> <li>Shengtao Zou (Tencent)</li> <li>Xinrui Yan (Tencent)</li> <li>Yang Zhou (New York University)</li> <li>Kaizhao Liang (SambaNova Systems)</li> <li>Tianren Gao (SambaNova Systems)</li> <li>Kuei-Da Liao (SambaNova Systems)</li> <li>Shan Bao (University of Michigan)</li> <li>Xuhui Kang (University of Virginia)</li> <li>Sean Sung-Wook Lee (University of Virginia)</li> <li>Amr Abdelraouf (Toyota Motor North America)</li> <li>Jianguo Cao (PediaMed AI)</li> <li>Jintai Chen (University of Illinois Urbana-Champaign)</li> </ul> <h2 id="citation">Citation</h2> <p>If the survey and our workshop inspire you, please cite our work:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@misc{cui2023survey,
      title={A Survey on Multimodal Large Language Models for Autonomous Driving}, 
      author={Can Cui and Yunsheng Ma and Xu Cao and Wenqian Ye and Yang Zhou and Kaizhao Liang and Jintai Chen and Juanwu Lu and Zichong Yang and Kuei-Da Liao and Tianren Gao and Erlong Li and Kun Tang and Zhipeng Cao and Tong Zhou and Ao Liu and Xinrui Yan and Shuqi Mei and Jianguo Cao and Ziran Wang and Chao Zheng},
      year={2023},
      eprint={2311.12320},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
</code></pre></div></div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> Â© Copyright 2023 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>